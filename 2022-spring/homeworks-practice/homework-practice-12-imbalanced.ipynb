{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCk9bUMos9A-"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "# Практическое задание 12. Несбалансированные задачи\n",
    "\n",
    "## Общая информация\n",
    "Дата выдачи: 06.06.2023\n",
    "\n",
    "Мягкий и жесткий дедлайны: 20.06.2023 23:59 MSK\n",
    "\n",
    "## Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "## Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-xx-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsiB3oacs9BG"
   },
   "source": [
    "## О задании\n",
    "\n",
    "В этом задании мы разберем основные техники работы в задачах, где один из классов занимает существенно меньшую долю выборки, чем остальные. Для простоты мы обойдемся бинарной задачей, тем не менее, во многом данные методы можно перенести и на задачи с б**о**льшим числом классов. Кроме того, вы получите очередной бесценный опыт исследования случайной библиотеки случайных индусов с нуля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9SXbBCjs9BH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5l0VsXHes9BI"
   },
   "source": [
    "**Задание -1 (1 балл)**. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIund96us9BI"
   },
   "source": [
    "В качестве данных для нашей работы возьмем выложенный на kaggle датасет транзакций, в котором нужно выискивать мошеннические проводки: [клик](https://www.kaggle.com/mlg-ulb/creditcardfraud). Данная задача по определению подходит под несбалансированную, что можно сказать даже без наличия каких-либо данных (понятно, что среди всех транзакций клиентов очень малая часть будет мошеннической).\n",
    "\n",
    "Загрузим данные, проведем некоторые классические манипуляции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tY2aKqhCs9BJ"
   },
   "outputs": [],
   "source": [
    "\"\"\"%%bash\n",
    "kaggle datasets download -d mlg-ulb/creditcardfraud\n",
    "unzip creditcardfraud.zip\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_UPWW51s9BJ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpJMyb0Hs9BJ",
    "outputId": "7f254a74-d248-47c6-9550-3e884e3cce92"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "St9c_rxKs9BK"
   },
   "source": [
    "Наши данные были анонимизированы. Мы имеем 30 признаков, из которых 28 - это результаты PCA-преобразования на исходном датасете. Еще 2 признака представляют собой время в секундах, прошедшее с момента первой транзакции в датасете, и размер транзакции. Скажите, какова доля положительных объектов в выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5P1I6lgs9BL"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eu2TTGCws9BL"
   },
   "source": [
    "Начнем с обработки времени. Секунды сами по себе не несут большой информации о зависимостях в данных, попробуйте по ним создать признаки \"час\" (от 0 до 23) и \"день\" (от 0 до ...) в аналогичной манере (принимая первый объект выборки за начальную точку). Сколько дней покрывают данные?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FW414k0js9BL"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QU5oagixs9BL"
   },
   "source": [
    "Постройте следующие графики:\n",
    "\n",
    "1. Распределение числа транзакций по каждому часу (line-plot).\n",
    "2. Распределение доли мошеннических транзакций по каждому часу (line-plot)\n",
    "3. То же самое для дней (здесь можно использовать bar-plot, так как дней должно быть немного).\n",
    "\n",
    "Какие выводы можно сделать из графиков? На ваш взгляд, как можно связать полученные нами часы с реальными часами в сутках?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGozHHXxs9BM"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kl7hLlhBs9BM"
   },
   "source": [
    "С анонимизированными признаками вряд ли можно придумать что-то интересное. Попробуйте (например, с помощью корреляции?) выбрать несколько наиболее важных признаков и поглядеть на различия в их распределении для разных классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfFy6Qhys9BM"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxCb9nars9BM"
   },
   "source": [
    "Теперь давайте разделим данные. Отделите хронологически последние 20% транзакций и поделите их пополам (также хронологически, т.е. без перемешивания) на валидационные и тестовые. Это разбиение не совсем корректно (как можно было заметить, мошеннические транзакции имеют разное распределение во времени - по-хорошему, нам стоило бы выделить целые сутки записей как под валидацию, так и под тест), тем не менее, мы не сможем получить больше данных для адекватного контроля, поэтому обойдемся этим. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XXA9XDjs9BN"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a06ZUN0Ms9BN"
   },
   "source": [
    "# Часть 1. Несбалансированная классификация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6Gaot3Fs9BN"
   },
   "source": [
    "**Задание 0. (1 балл)**: перед началом работы давайте поговорим о том, как мы будем оценивать качество. Классические метрики для качества классификации чаще всего \"ломаются\" на задачах с сильным перекосом. Чему будет равно значение accuracy для наивного предсказания (= мажорный класс для каждого объекта)? (можете не отвечать, просто подумайте)\n",
    "\n",
    "Из курса МО-1 вам уже известно, что мы можем использовать в таких задачах `AUC-PR` и получать адекватные показатели. Можно сказать, что `AUC-PR` представляет собой матожидание `precision` по распределению, заданному выигрышем в `recall` при смене порога. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FN144XVps9BO"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haRPLskDs9BO"
   },
   "source": [
    "Тем не менее, существуют и другие, не менее интересные метрики. Одной из таких метрик является коэффициент Каппа Коэна, представляющий собой нормализованную `accuracy`:\n",
    "\n",
    "$$\\kappa = \\frac{p_o - p_e}{1 - p_e}$$\n",
    "\n",
    "Данная метрика служит в качестве меры согласованности между двумя независимыми предсказателями, но ничего не знает про \"верные\" и \"предсказанные\" метки (в отличие от многих других метрик машинного обучения). Здесь $p_o$ - доля согласованных предсказаний, а $p_e$ - доля согласованных предсказаний, которая могла бы получиться при случайных ответах предсказателей. В нашем случае это работает так:\n",
    "\n",
    "• В качестве $p_o$ берем accuracy\n",
    "\n",
    "• В качестве $p_e$ примем следующую величину - вероятность случайного соглашения позитивных ответов (произведение долей позитивных ответов в обоих предсказаниях) плюс вероятность случайного соглашения негативных ответов (произведение долей негативных ответов в обоих предсказаниях)\n",
    "\n",
    "Метрика принимает значения от -1 до 1, где 1 - полная согласованность, 0 - согласованность на уровне рандома, -1 - совсем плохо. Как уже говорилось, метрика не различает \"верные\" и \"предсказанные\" метки, поэтому является симметричной (можете использовать это для отладки):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LC4U_7ays9BO"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vldIZwrMs9BP"
   },
   "source": [
    "Еще одной метрикой в такой задаче служит коэффициент корреляции Мэтьюза, выражающийся в терминах матрицы ошибок следующим образом:\n",
    "\n",
    "$$\\text{MCC} = \\frac{TP\\times TN - FP \\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$$ \n",
    "\n",
    "Метрика принимает значения от -1 до 1, интерпретируемые аналогичным образом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsKSZScts9BP"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaOHYiZPs9BP"
   },
   "source": [
    "Обратите внимание, что эти метрики вычисляются на бинаризованных предсказаниях, поэтому может иметь смысл дополнительная настройка порога бинаризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBsLuK2ds9BQ"
   },
   "source": [
    "Давайте проверим, что наши метрики действительно подходят под задачу. Вычислите их значения для наивного предсказания (aka мажорный класс для всех объектов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LM_Q37gAs9BQ"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwryyw3ts9BQ"
   },
   "source": [
    "Давайте запустим бейзлайн-решение для нашей задачи. С чего же начнем? Возьмите `catboost` и обучите его классификатор на наших данных (используйте все признаки). Вычислите значения всех метрик на тестовой части, для контроля переобучения используйте валидационную (здесь и далее везде, где фигурирует `catboost`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3R-MRd7s9BQ"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFFhboVQs9BR"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zs-ZjQDLs9BR"
   },
   "source": [
    "Если вы все сделали правильно, у вас должны были получиться значения в районе 0.7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slOmV65fs9BR"
   },
   "source": [
    "**Задание 1. (1 балл)**. Многие реализации методов предлагают встроенные способы для борьбы с нашей проблемой. Самое часто встречающееся решение - просто добавить вес в функции потерь для минорного класса (таким образом, ошибка на объекте минорного класса будет весить больше, чем для мажорного). В `catboost` это также реализовано, причем для бинарной задачи это можно сделать целыми двумя способами (можете выбрать любой, на свой вкус, автор задания предпочитает отдельный скейлинг для минорного класса). Чаще всего в качестве веса берется отношение числа объектов мажорного класса к числу минорного. Попробуйте обучить модель с таким скалированием и сравните метрики на тестовой части с бейзлайном."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLVjSc0As9BR"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwhhGSVVs9BR"
   },
   "source": [
    "Поскольку данный вес будет являться гиперпараметром метода, было бы опрометчиво остановиться на одном значении (тем более, с большой вероятностью у вас все сломалось). Запустите перебор для этого гиперпараметра на валидационной выборке (используйте `PR-AUC`), подберите оптимальный порог бинаризации для $\\kappa$ или $\\text{MCC}$. Для лучшего найденного веса и порога вычислите все метрики на тестовой части. \n",
    "\n",
    "При этом можете также проверить отдельное скалирование в большую сторону для мажорного класса (т.е. веса минорного сделать меньше 1) и экстремальные скалирования (т.е. веса минорного больше, чем в начале этого задания). Какой вес получился оптимальным?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LluYkXus8OWt"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SaQ-j2Ss9BS"
   },
   "source": [
    "**Задание 2. (1 балл)**. На самом деле, то, что мы сейчас делали, очень схоже с другой распространенной техникой - оверсэмплингом. Фактически, мы можем продублировать все объекты минорного класса и получить тот же эффект, какой был бы при использовании веса, равного 2. Тем не менее, такой подход - это лишь малая часть того, что мы можем проделать с целью повысить число объектов минорного класса. \n",
    "\n",
    "Для продолжения работы установим библиотеку [imbalanced-learn](https://imbalanced-learn.org/stable/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHL5jywds9BS"
   },
   "outputs": [],
   "source": [
    "!pip3 install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-dF_oXps9BS"
   },
   "source": [
    "Первый метод, которым мы воспользуемся, называется SMOTE (его вы уже разбирали на лекции). Кратко напомним суть: мы выбираем случайного кандидата среди $k$ ближайших соседей объекта минорного класса, затем берем точку на отрезке между двумя объектами (т.е. выпуклую комбинацию со случайными коэффициентами) и добавляем в выборку. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcWmeujGs9BS"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pke-fWMGs9BT"
   },
   "source": [
    "Используйте SMOTE для ресэмплинга обучающей выборки, на новой выборке обучите модель (вес положительных объектов скалировать не нужно). Замерьте качество на тестовой выборке (**важно!** не преобразовывайте валидационную и тестовую выборку никак - мы не хотим отслеживать качество на объектах, которых в реальности не существует). Сравните полное выравнивание выборки с частичным (т.е. таким, что баланс классов улучшается, но не достигает равенства - скажем, 1:2 и 1:10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xm3HED1ms9BT"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_3MA21rs9BT"
   },
   "source": [
    "**Бонус (1.5 балла)**. Для vanilla SMOTE существуют некоторые модификации, часть из которых была реализована в библиотеке imblearn. Во время лекций/семинаров эти модификации не рассматривались, тем не менее, мы все равно их исследуем.\n",
    "\n",
    "Найдите статьи о следующих методах и попробуйте вкратце сформулировать, в чем их основная идея (сделайте так, чтобы человек, знакомый с машинным обучением в целом, но не слышавший конкретно про это смог понять):\n",
    "\n",
    "BorderlineSMOTE - \n",
    "\n",
    "SVM-SMOTE - \n",
    "\n",
    "K-Means-SMOTE - \n",
    "\n",
    "ADASYN - \n",
    "\n",
    "Теперь попробуйте сравнить качество всех методов на наших данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cw5hLd-6s9BT"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvVG5osbs9BU"
   },
   "source": [
    "**Задание 3. (1 балл)**. До этого момента все наши решения концентрировались на работе с минорным классом. Теперь давайте попробуем зайти с другой стороны. Может быть, для восстановления закономерностей нам не нужно столько объектов мажорного класса, и они просто засоряют нам выборку лишней информацией?\n",
    "\n",
    "Для решения этой проблемы существуют методы андерсэмплинга. Самое простое, что можно придумать - удалять точки мажорного класса, пока мы не получим приемлемый баланс. Протестируйте следующий метод и постройте графики достигаемых значений метрик от баланса классов и от отношения размеров исходной и пересэмпленной выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZQymG9Rs9BU"
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRysrdxhs9BU"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-onGH2ts9BU"
   },
   "source": [
    "Даже такой наивный подход может дать относительно неплохие результаты и улучшить наши метрики. Тем не менее, сейчас мы никак не используем информацию о распределении объектов в выборке. Оказывается, что даже относительно простые эвристические правила могут заметно поднять нам качество - например, мы можем при отбрасывании использовать близость отдельных объектов мажорного класса к минорному и отбрасывать самые близкие. Протестируйте алгоритм [Near-Miss](https://www.site.uottawa.ca/~nat/Workshop2003/jzhang.pdf) на наших данных и постройте графики, аналогичные предыдущему пункту (также добавьте график с зависимостью качества от числа соседей)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXhxPmEUs9BU",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9z_OwXkps9BV"
   },
   "source": [
    "**Бонус (1 балл)**. imblearn также предлагает много различных методов для андерсэмплинга. Выберите что-нибудь еще из предлагаемого на свой вкус, опишите идею метода и протестируйте его.\n",
    "\n",
    "**Бонус (2 балла)**. Сможете ли вы с помощью комбинации любых методов оверсэмплинга, андерсэмплинга и классификации набрать 0.8 на всех трех метриках?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXrq_R_Ks9BV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBf-rrmcs9BV"
   },
   "source": [
    "# Часть 2. Поиск аномалий. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UBhTHszs9BV"
   },
   "source": [
    "Как вы могли заметить, методы балансировки выборок очень часто могут привести к не самым лучшим результатам из-за того, что они по сути искажают информацию о реальном распределении данных - в реальности обычно требуется долгий подбор в принципе работоспособных для задачи методов и их аккуратная настройка. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSYVXvmxs9BV"
   },
   "source": [
    "Теперь давайте попробуем слегка сменить постановку задачи и переключиться на задачу \"одноклассовой\" классификации, то есть - поиска *аномалий* в выборке. В общем-то, это вполне согласуется с нашей областью работы - мы действительно можем назвать мошеннические транзакции аномальньми (как интуитивно, так и на основании наблюдаемой балансировки данных). \n",
    "\n",
    "Стоит отметить, что методы обнаружения аномалий чаще всего относятся к классу методов обучения без учителя. Это дает некоторый положительный эффект - нам не обязательно нужно тратить время на разметку данных (тем не менее, для контроля качества какую-то часть разметить все-таки придется). Впрочем, чаще всего перфоманс таких методов оказывается заметно хуже, чем у честного обучения с учителем (если мы можем себе его позволить).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrRy0uOAs9BW"
   },
   "source": [
    "**Задание 4. (3 балла).** На занятиях вы разбирали схожий с Random Forest подход для детекции аномалий без известной разметки данных, называемый Isolation Forest. Напомним суть: на этапе обучения мы создаем ансамбль из решающих деревьев, в котором признак и порог на каждую вершину подбираются случайно. Затем мы считаем для объектов оценку аномальности через длину пути до соответствующего листа в каждом дереве.\n",
    "\n",
    "В данном задании вам предлагается реализовать модификацию данного алгоритма, известную как Extended Isolation Forest. В ней мы на каждом шаге будем определять не порог для признака, а полноценную случайную гиперплоскость, разбивающую выборку на 2 части. С детальным описанием вы можете ознакомиться [здесь](https://arxiv.org/pdf/1811.02141.pdf).\n",
    "\n",
    "Ниже приведен шаблон кода. Постарайтесь работать в его рамках (минорные изменения вполне допустимы, главное не переворачивайте всю структуру с ног на голову). \n",
    "\n",
    "**NB**: будем считать, что в нашем датасете нет категориальных признаков - можете не заморачиваться с их обработкой (но в общем случае, это будет важно).\n",
    "\n",
    "**Советы**:\n",
    " - Численные признаки лучше предобработать надлежащим образом.\n",
    " - Возможно, вам поможет выбрасывание некоторых признаков.\n",
    " - Внимательно следите за знаками.\n",
    " - Не игнорируйте документирующие строки.\n",
    " - Вероятнее всего, вы не сможете приблизиться по качеству к supervised-решениям. Если у вас не получается это сделать (но вы уверены в своей правоте), не стоит тратить слишком много времени на поиск ошибок.\n",
    "\n",
    "\n",
    "\n",
    "**Бонусы (каждый по 0.5)**:\n",
    "- Сделайте ваш EIF параллельным (`multiprocessing`, `joblib`).\n",
    "- Добавьте возможность откатиться к дефолтному варианту Isolation Forest. (порассуждайте, как можно реализовать это в данной модели?):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HsFj1XR2s9BW"
   },
   "outputs": [],
   "source": [
    "def c_factor(n):\n",
    "    \"\"\"\n",
    "    Computes average path length for an unsuccessful search in a binary search tree.\n",
    "    Params:\n",
    "        n: int - number of data points for BST\n",
    "    \"\"\"\n",
    "    #your code here\n",
    "\n",
    "def calc_height(X, depth, node):\n",
    "    \"\"\"\n",
    "    Calculates anomaly scores for sample in a recursive manner.\n",
    "    Params:\n",
    "        X: np.array - current sample, available to node\n",
    "        \n",
    "        depth: int - path length up to current node\n",
    "        \n",
    "        node: Node - current tree node\n",
    "        \n",
    "    Returns:\n",
    "        scores: int, float or np.array - anomaly scores for sample\n",
    "    \"\"\"\n",
    "    scores = np.zeros(X.shape[0])\n",
    "\n",
    "    #your code here\n",
    "\n",
    "\n",
    "class Node(object):\n",
    "    \"\"\"\n",
    "    A single node object for each tree. Contains information on height, current data,\n",
    "    splitting hyperplane and children nodes.\n",
    "    \n",
    "    Attributes:\n",
    "        X: np.array - data available to current node\n",
    "        size: int - length of available data\n",
    "        \n",
    "        depth: int - depth of node\n",
    "\n",
    "        left: Node - left child\n",
    "        right: Node - right child\n",
    "\n",
    "        kind: str - either \"internal\" or \"external\", indicates the type of current node\n",
    "\n",
    "        w: np.array - normal vector for the splitting hyperplane\n",
    "        b: float - intercept term for the splitting hyperplane\n",
    "    \"\"\"\n",
    "    def __init__(self, X, depth, left, right, kind, w, b):\n",
    "        \"\"\"\n",
    "        Node(h, left, right, kind, w, b)\n",
    "        Represents the node object.\n",
    "        \n",
    "        Params:\n",
    "            X: np.array - data available to current node\n",
    "            depth: int - depth of node\n",
    "            \n",
    "            left: Node - left child\n",
    "            right: Node - right child\n",
    "            \n",
    "            kind: str - either \"internal\" or \"external\", indicates the type of current node\n",
    "            \n",
    "            w: np.array - normal vector for the splitting hyperplane\n",
    "            b: float - intercept term for the splitting hyperplane\n",
    "            \n",
    "        \"\"\"\n",
    "        self.size = len(X)\n",
    "        \n",
    "        self.depth = depth\n",
    "        \n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        \n",
    "        self.kind = kind\n",
    "    \n",
    "        self.w = w\n",
    "        self.b = b\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        For convenience only.\n",
    "        \"\"\"\n",
    "        return f\"Node(size={self.size}, depth={self.depth}, kind={self.kind})\"\n",
    "\n",
    "class RandomizedTree(object):\n",
    "    \"\"\"\n",
    "    Single randomized tree object. Stores root and its depth (tree is built recursively).\n",
    "    Attributes:\n",
    "        depth: int - current tree depth\n",
    "        \n",
    "        max_depth: int - maximum tree depth\n",
    "        \n",
    "        root: Node - root node \n",
    "\n",
    "        internal_count: int - number of internal nodes\n",
    "\n",
    "        external_count: int - number of external nodes\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, X, max_depth):\n",
    "        \"\"\"\n",
    "        Single randomized tree object. Stores root and its depth (tree is built recursively).\n",
    "        Params:\n",
    "            X: np.array - train sample\n",
    "            max_depth: int - maximum tree depth\n",
    "\n",
    "        \"\"\"\n",
    "        self.depth = 0\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        self.internal_count = 0\n",
    "        self.external_count = 0\n",
    "\n",
    "        self.root = self.grow(X, 0)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        For convenience only.\n",
    "        \"\"\"\n",
    "        \n",
    "        return f\"RandomizedTree(depth={self.depth}, max_depth={self.max_depth}, n_internal={self.internal_count}, n_external={self.external_count})\"\n",
    "\n",
    "        \n",
    "        \n",
    "    def grow(self, X, depth):\n",
    "        \"\"\"\n",
    "        Grow tree in a recursive manner.\n",
    "        Params:\n",
    "            X: np.array - available train sample\n",
    "            \n",
    "            depth: int - current tree depth\n",
    "            \n",
    "        Returns:\n",
    "            node: Node - a trained node with separating hyperplane data.\n",
    "                         Node provides access to children if necessary (these are built recursively)\n",
    "        \"\"\"\n",
    "        #your code here\n",
    "            \n",
    "        return Node(X, depth, left, right, kind, w, b)\n",
    "\n",
    "    def score_samples(self, X):\n",
    "        \"\"\"\n",
    "        Calculate anomaly scores for given data. You may utilize outer function `calc_height`.\n",
    "        Params:\n",
    "            X: np.array - data to be evaluated\n",
    "            \n",
    "        Returns:\n",
    "            scores: np.array - estimated anomaly scores\n",
    "        \"\"\"\n",
    "        #your code here\n",
    "\n",
    "        return scores\n",
    "        \n",
    "    \n",
    "class ExtendedIsolationForest(object):\n",
    "    \"\"\"\n",
    "    Extended Isolation Forest object. Stores training data and trained randomized trees.\n",
    "    Attributes:\n",
    "        n_trees: int - number of Randomized Trees\n",
    "        \n",
    "        max_depth: int - maximum depth of each tree\n",
    "        \n",
    "        subsample_rate: float - draw `subsample_rate * X.shape[0]` samples for each tree\n",
    "        \n",
    "        trees: list - container for trained trees \n",
    "        \n",
    "        contamination: float - estimated fraction of anomaly samples in data. Used for thresholding\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_trees, subsample_rate, max_depth=None, contamination=0.01):\n",
    "        \"\"\"\n",
    "        Extended Isolation Forest object. Stores training data and trained randomized trees.\n",
    "        Params:\n",
    "            n_trees: int - number of Randomized Trees\n",
    "\n",
    "            subsample_rate: float - draw `subsample_rate * X.shape[0]` samples for each tree\n",
    "\n",
    "            max_depth: int or None - maximum depth of each tree. Defaults to ceil(log_2(subsample_size)) if not provided\n",
    "\n",
    "            contamination: float - estimated fraction of anomaly samples in data. Used for thresholding\n",
    "\n",
    "        \"\"\"\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.subsample_rate = subsample_rate\n",
    "        self.trees = []\n",
    "        self.contamination = contamination\n",
    "        self.is_fit = False\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\"For convenience only.\"\"\"\n",
    "        \n",
    "        return f\"ExtendedIsolationForest(n_trees={self.n_trees}, max_depth={self.max_depth}, subsample_rate={self.subsample_rate}, contamination={self.contamination}, is_fit={self.is_fit})\"\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fit EIF to new data.\n",
    "        Params:\n",
    "            X: np.array - 2d array of samples\n",
    "        \"\"\"\n",
    "        #your code here\n",
    "        return self\n",
    "    \n",
    "    def score_samples(self, X):\n",
    "        \"\"\"\n",
    "        Estimate (normalized) anomaly score for each given sample\n",
    "        Params:\n",
    "            X: np.array - new samples\n",
    "\n",
    "        Returns:\n",
    "            scores: np.array - anomaly scores (larger value means higher probability of a sample being an outlier)\n",
    "        \"\"\"\n",
    "        #your code here\n",
    "\n",
    "        return scores\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict if given samples are outliers.\n",
    "        Params:\n",
    "            X: np.array - new samples\n",
    "\n",
    "        Returns:\n",
    "            labels: np.array - anomaly labels (1 for outliers, 0 for inliers)\n",
    "        \"\"\"\n",
    "        #your code here\n",
    "\n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9ikebErs9BX"
   },
   "source": [
    "**Задание 5. (1 балл).** Протестируйте вашу реализацию EIF и подберите оптимальные гиперпараметры (наш метод не использует разметку, поэтому можете попробовать делать это на обучающей выборке). Сравните ее с обычным IF из `sklearn` (желательно делать это на одних и тех же параметрах). Удалось ли сделать лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7INFCxvKs9BX"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G00BCRJj4Sz3"
   },
   "source": [
    "Возможно, ваш алгоритм выдал большие оценки объектам с негативной разметкой. Постарайтесь выбрать несколько таких объектов и доступно объяснить (= с кодом и графиками), почему так вышло:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ds6Rz3a-4s9V"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLpfrhGFs9BX"
   },
   "source": [
    "**Задание 6. (1 балл).** `sklearn` также предлагает нам и другие методы для поиска аномалий. В этом задании мы предлагаем вам сделать следующее:\n",
    "\n",
    "Для начала попробуйте использовать методы Local Outlier Factor и One-Class SVM. Сравните результаты с IF и EIF.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vs8q00tXs9BX"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGY_u8nts9BX"
   },
   "source": [
    "У вас началась депрессия из-за плохих метрик? Не беда! Сейчас давайте сделаем так: все методы, опробованные в этой части, попробуем задействовать для создания дополнительных признаков в данных. Проделайте это (не забудьте, что обучаться здесь нужно на трейне). Теперь возьмите лучшую модель из предыдущей части и обучите на новых данных. Смогли ли unsupervised-методы повысить вам качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3QpV-Hgs9BY"
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiGbNcXHs9BY"
   },
   "source": [
    "**Бонус. (0.1 балла).**\n",
    "\n",
    "При сдаче проверяющий запустит следующую клетку один раз. Если она даст положительный результат, вы получите 0.1 бонусных балла. Если она даст отрицательный результат, вы получите -0.1 бонусных балла. \n",
    "\n",
    "Если вы хотите отказаться от сдачи данного задания, допишите \"хочу\" после двоеточия: `your text here`\n",
    "\n",
    "Ниже вы можете попрактиковаться и оценить ваши силы (изменять код ячейки запрещается!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfgJoZ_ns9BY"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rng = random.SystemRandom(0)\n",
    "rng.uniform(-1.0, 1.0)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "imbalanced-hw-clean.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
