\documentclass[12pt,fleqn]{article}
\usepackage{vkCourseML}
\hypersetup{unicode=true}
%\usepackage[a4paper]{geometry}
\usepackage[hyphenbreaks]{breakurl}

\interfootnotelinepenalty=10000

\begin{document}
\title{Лекция 20\\Рекомендательные системы}
\author{Е.\,А.\,Соколов\\ФКН ВШЭ}
\maketitle

\section{Метрики качества рекомендаций}

Существует достаточно много метрик качества рекомендательных систем~--- некоторые связаны
с точностью предсказания, а некоторые оценивают продуктовые аспекты~(например, среднее
качество тех фильмов, которые обычно рекомендуются).
Нет общих советов по поводу того, на какую метрику имеет смысл обращать внимание.
Один из возможных подходов~--- выбрать ключевую с точки зрения бизнеса онлайн-метрику~(например,
среднее время, которое пользователь проводит на сайте интернет-магазина, средний чек или что-то ещё),
а затем выбрать оффлайн-метрику или линейную комбинацию оффлайн-метрик, которая лучше
всего коррелирует с ключевой метрикой.
Здесь под онлайн-метрикой понимается показатель, который можно измерить
только при запуске рекомендательной системы на реальных пользователях,
а под оффлайн-метрикой~--- функцию, которую можно оценить, построив
предсказания модели на исторических данных.
Также иногда пытаются найти промежуточную онлайн-метрику, которая коррелируют с основной,
но при этом быстрее реагирует на изменения в работе рекомендательной системы~--- но эту
тему мы пока не будем затрагивать.
Разберём несколько оффлайн-метрик.

\subsection{Качество предсказаний}
Поскольку рекомендательная система обучается предсказывать оценки~$r_{ui}$,
логично оценивать качество решения именно этой задачи.

\paragraph{Предсказание рейтингов.}
Если модель предсказывает рейтинг или другую вещественную величину~(например, длительность просмотра),
то качество может измеряться через MSE, RMSE, MAE или другие регрессионные метрики.

\paragraph{Предсказание событий.}
Если модель предсказывает вероятность некоторого события~(клика, покупки, просмотра, добавления в корзину),
то качество можно измерять с помощью метрик качества классификации~--- доля правильных ответов, точность, полнота, F-мера,
AUC-ROC, AUC-PR, log-loss и т.д.

Также можно учитывать, что мы показываем пользователю только~$k$ товаров, получивших самые высокие
предсказания модели, и нас интересует лишь качество этих товаров.
Если через~$R_u(k)$ обозначить лучшие~$k$ товаров для пользователя~$u$ с точки зрения модели,
а через~$L_u$ товары, для которых действительно произошло интересующее нас событие,
то можно ввести следующие метрики:
\begin{itemize}
    \item Наличие верной рекомендации: $\text{hitrate@k} = [R_u(k) \cap L_u \neq \emptyset]$;
    \item Точность: $\text{precision@k} = \frac{|R_u(k) \cap L_u|}{|R_u(k)|}$;
    \item Полнота: $\text{recall@k} = \frac{|R_u(k) \cap L_u|}{|L_u|}$.
\end{itemize}

\paragraph{Качество ранжирования.}
Вообще говоря, нам не очень важно, насколько точно модель предсказывает рейтинг или вероятность клика~---
от неё лишь требуется дать более релевантным товарам более высокие предсказания.
Это значит, что модель должна правильно ранжировать~(или сортировать) товары.

Одной из популярных метрик качества ранжирования является nDCG.
Обозначим через~$a_{ui}$ предсказание модели для пользователя~$u$ и товара~$i$.
Отсортируем все товары по убыванию предсказания~$a_{ui}$.
Тогда для товара~$i_p$ на позиции~$p$ можно вычислить его полезность~$g(r_{ui_p})$
и штраф за позицию~$d(p)$.
Метрика DCG задаётся как
\[
    \text{DCG@k}(u)
    =
    \sum_{p = 1}^{k}
        g(r_{ui_p}) d(p).
\]
Примерами конкретных функций могут служить~$g(r) = 2^{r} - 1$ и~$d(p) = \frac{1}{\log(p + 1)}$.
Чтобы значение метрики легче было интерпретировать, её можно поделить на значение DCG
при идеальном ранжировании~--- в этом случае получим метрику nDCG~(normalized DCG):
\[
    \text{nDCG@k}(u)
    =
    \frac{
        \text{DCG@k}(u)
    }{
        \max \text{DCG@k}(u)
    }.
\]
Далее значение nDCG можно усреднить по всем пользователям.

\paragraph{Недостатки оценок качества предсказания.}
Основная проблема состоит в том, что качество предсказания само по себе не определяет
пользу рекомендательной системы.
Модель может идеально угадывать то, что купил пользователь~--- но, возможно, он приобрёл бы
эти товары и без рекомендаций.
Поскольку мы никогда не можем узнать, повлияли ли рекомендации на намерения пользователя,
имеет смысл анализировать и другие метрики качества, которые могут косвенно
говорить о пользе предсказаний модели~\cite{shani11eval}.

\subsection{Покрытие}
%Покрытие товаров (доля когда-либо рекомендованных, энтропия распределения частоты успехов товаров)

%Покрытие пользователей (скольки пользователям мы никогда не показываем рекомендации)

\paragraph{Покрытие товаров.}
Полезно обращать внимание на то, какая доля товаров в принципе рекомендуется пользователям~---
так, может оказаться, что модель показывает только самые популярные товары,
а большая часть ассортимента игнорируется.
В качестве простейшей метрики можно использовать~\emph{покрытие каталога},
которые вычисляется как доля товаров, порекомендованных хотя бы один раз.

Также можно оценить общее разнообразие рекомендаций.
Пусть~$p(i)$~--- доля показа товара~$i \in I$ среди всех показов для данной рекомендательной системы.
Тогда разнообразие можно определить как энтропию такого распределения:
\[
    H(p)
    =
    -\sum_{i \in I}
        p(i) \log p(i).
\]

\paragraph{Покрытие пользователей.}
Рекомендательная система может быть устроена так, что некоторым пользователям вообще ничего не рекомендуется~---
например, из-за низкой уверенности классификаторов или отсутствия тех или иных признаков для модели.
Имеет смысл вычислять долю пользователей, для которых не рекомендуется ни одного товара,
чтобы отслеживать проблемы с покрытием в модели рекомендаций.

\subsection{Новизна}
%Какая доля новых для пользователя товаров среди рекомендованных?

%Можно спросить пользователя

%Можно удалить часть рейтингов из прошлого (пользователь видел их где-то ещё)
%и понижать метрику, если что-то из них рекомендуется.

%Можно измерять долю показов среди непопулярных товаров.

Под новизной понимается доля новых для пользователя товаров среди рекомендованных.
При этом под новыми понимаются те товары, которые пользователь видит впервые глобально,
а не только на нашем сайте~--- в идеале хочется уметь угадывать, какие товары пользователь
встречал раньше на других ресурсах.

Можно предложить несколько подходов к измерению новизны:
\begin{itemize}
    \item Для каждого рекомендованного товара добавить в интерфейсе возможность
        сообщить о том, что этот товар пользователь уже видел.
    \item Удалить из обучающей выборки часть товаров, которые пользователь купил или просмотрел~---
        тем самым мы будем моделировать ситуацию, в которой пользователь когда-то раньше
        узнал про этот товар, но в наших данных это не отражено.
        Далее будем оценивать новизну на основе того, как часто эти удалённые товары попадают
        в рекомендации.
    \item Можно считать, что пользователь с большей вероятностью встречал раньше популярные товары
        и с меньшей~--- непопулярные.
        Тогда новизну можно вычислять как долю угаданных рекомендательной системой товаров,
        где каждый товар имеет вес, обратно пропорциональный популярности этого товара.
\end{itemize}

\subsection{Прозорливость~(serendipity)}
%Способность угадывать непопулярные предпочтения

%Или способность удивлять пользователя

%Можно измерять как долю рекомендаций, который далеки от всех оценённых пользователем товаров.
%Пример расстояния: $d(b, B) = \frac{1 + c_B - c_{B, w(b)}}{1 + c_B}$.

Под прозорливостью понимается способность рекомендательной системы предлагать товары,
которые отличаются от всех купленных пользователем ранее.
Например, если пользователь читал только книги конкретного автора,
то рекомендацию хорошей с точки зрения пользователя книги, но от другого автора,
мы будем называть прозорливой.

Прозорливость можно измерять как долю рекомендаций, которые далеки от всех оценённых пользователем товаров.
Рассмотрим пример с рекомендациями книг.
Допустим, мы хотим измерить расстояние~$d(b, B)$ между новой книгой~$b$ и множеством уже оценённых книг~$B$.
Обозначим через~$c_{B, w}$ число книг от автора~$w$ в множестве~$B$,
а через~$c_B$~--- максимальное количество книг от одного автора в~$B$.
Тогда расстояние можно определить как
\[
    d(b, B) = \frac{1 + c_B - c_{B, w(b)}}{1 + c_B},
\]
где~$w(b)$~--- автор книги~$b$.

\subsection{Разнообразие}
%Насколько товары из одной пачки рекомендаций отличаются друг от друга

%Например, среднее попарное расстояние между товарами в пачке

Под разнообразием понимается степень сходства товаров внутри одной пачки рекомендаций~(т.е. тех товаров,
которые одновременно рекомендуются пользователю).
Логично ожидать, что полезность набора из 10 чехлов фотоаппаратов ниже,
чем набора из чехла, линзы, объектива, батареек и т.д.~--- именно это и должна оценивать метрика разнообразия.
Можно её задавать как, например, среднее попарное расстояние между товарами в одной пачке.
Расстояние может измеряться по каталогу~(как далеко в дереве категорий товаров находятся эти два товара) или, например,
по аналогии с item-to-item рекомендациями~(насколько эти два товара пересекаются по множествам купивших их пользователей).

\section{Архитектура рекомендательных систем}

В рекомендательной системе может участвовать очень большое количество товаров.
При каждом посещении пользователем веб-страницы, где есть блок рекомендаций,
необходимо выдать ему~$k$ наиболее подходящих товаров, причём достаточно быстро~(пользователь не может
ждать минуту, пока загрузится страница).
В хорошей рекомендательной системе участвуют сотни признаков~--- их вычисление для каждого товара,
а затем ещё и применение ко всем товарам градиентного бустинга или графа вычислений вряд ли
получится успеть сделать за 1 секунду.
Из-за этого рекомендательные системы работают в несколько этапов: обычно всё начинается с отбора кандидатов,
где быстрая модель выбирает небольшое количество~(тысячи или десятки тысяч) товаров,
а затем только для этих товаров вычисляется полный набор признаков и применяется полноценная модель.
В качестве быстрой модели может выступать линейная модель на нескольких самых важных признаках или, например,
простая коллаборативная модель.


\begin{thebibliography}{1}
\bibitem{gillis12hals}
    \emph{Gillis, Nicolas and Glineur, Fran\c{c}ois} (2012).
    Accelerated Multiplicative Updates and Hierarchical Als Algorithms for Nonnegative Matrix Factorization.~//
    Neural Comput., 24, 4, p. 1085--1105.
\bibitem{hu08ials}
    \emph{Hu, Yifan and Koren, Yehuda and Volinsky, Chris} (2008).
    Collaborative Filtering for Implicit Feedback Datasets.~//
    ICDM '08.
\bibitem{rendle12fm}
    \emph{Rendle, S.} (2012).
    Factorization machines with libFM.~//
    ACM Trans. Intell. Syst. Technol. 3, 3, Article 57.
\bibitem{ffm}
    Field-aware Factorization Machines: \\\url{http://www.csie.ntu.edu.tw/\~r01922136/slides/ffm.pdf}
\bibitem{shani11eval}
    \emph{Guy Shani, Asela Gunawardana} (2011).
    Evaluating recommendation systems.~//
    Recommender systems handbook, pp. 257-297. Springer.
\end{thebibliography}



\end{document}
