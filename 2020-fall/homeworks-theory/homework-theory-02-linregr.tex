\documentclass[12pt,fleqn]{article}

\usepackage{vkCourseML}

\usepackage{lipsum}
\usepackage{indentfirst}
\title{Машинное обучение, ФКН ВШЭ\\Линейная регрессия}
\author{}
\date{}
\theorembodyfont{\rmfamily}
\newtheorem{esProblem}{Задача}
\begin{document}

\maketitle

\begin{esProblem}
    Докажите, что оценка градиента, получаемая методом mini-batch gradient descent, является несмещенной.
\end{esProblem}

\begin{esProblem}
    Допустим, что обучающая выборка состоит из $2\ell$ объектов и верно следующее: $y_i = -y_{\ell + i} \ne 0, i = 1 \dots \ell$. Рассмотрим константное предсказание $a(x) = C$. Найдите оптимальное значение $C$ с точки зрения функционала MAPE.
\end{esProblem}

\begin{esProblem}
    Рассмотрим две задачи линейной регрессии с $L_1$- и $L_2$-регуляризацией и одинаковыми коэффициентами $\lambda > 0$:
    \[
        \|Xw - y\|^2_2 + \lambda \|w\|_1 \rightarrow \displaystyle\min_{w} \quad (1)
    \]
    \[
        \|Xw - y\|^2_2 + \lambda \|w\|_2 \rightarrow \displaystyle\min_{w} \quad (2)
    \]
    Пусть их решения равны, соответственно, $w_1^*$ и $w_2^*$. Можно ли уттверждать, что $\|w_1^*\|_1 < \|w_2^*\|_1$? А что $\|w_2^*\|_2 < \|w_1^*\|_2$?
\end{esProblem}

\begin{esProblem}
    Убедитесь, что вы знаете ответы на следующие вопросы:
    \begin{itemize}
        \item Почему~$L_1$-регуляризация производит отбор признаков?
        \item Почему коэффициент регуляризации нельзя подбирать по обучающей выборке?
        \item Почему накладывать регуляризатор на свободный коэффициент~$w_0$ может быть плохой идеей?
        \item Что такое кросс-валидация, чем она лучше использования отложенной выборки?
        \item Почему категориальные признаки нельзя закодировать натуральными числами? Что такое one-hot encoding?
        \item Для чего нужно масштабировать матрицу объекты-признаки перед обучением моделей машинного обучения?
        \item Почему MSE чувствительно к выбросам?
    \end{itemize}
\end{esProblem}

\end{document}
