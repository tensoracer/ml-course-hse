\documentclass[12pt,fleqn]{article}
\usepackage{vkCourseML}

\theorembodyfont{\rmfamily}
\newtheorem{esProblem}{Задача}

\begin{document}
\pagenumbering{gobble}
\title{Машинное обучение\\ФКН ВШЭ\\Теоретическое домашнее задание №2}
\date{}
\author{}
\maketitle

\begin{esProblem}
    Найдите константу C, решающую следующую задачу ($0 < \tau < 1$ фиксировано):
    \[
    \sum_{i=1}^\ell \rho_\tau (y_i - C) \rightarrow \min_{C},
    \]
    \[
    \rho_\tau(x) = \begin{cases} \tau x, \quad x > 0, \\ (\tau - 1) x, \quad x \leqslant 0. \end{cases}
    \]
\end{esProblem}

\begin{esProblem}
    Покажите, что если в задаче регрессии $p(y_i|x_i, w) = \frac \alpha 2 \exp \bigl( -\alpha \bigl|y_i - w^Tx_i\bigr| \bigr)$ (распределение Лапласа,  $\alpha$ фиксировано), то метод максимального правдоподобия эквивалентен оптимизации MAE для модели линейной регрессии.
\end{esProblem}

\begin{esProblem}
	Представим, что в некоторой задаче мы можем разбить признаки на $k$ непересекающихся групп (например, такие группы возникают при использовании one-hot кодирования  --- по одной группе бинарных признаков на каждый категориальный признак). Кроме того, мы хотим в модели линейной регрессии задать свой ненулевой коэффициент $L_2$---регуляризации для каждой группы. Какому априорному распределению на веса это будет соответствовать?
\end{esProblem}

\begin{esProblem}
    Убедитесь, что вы знаете ответы на следующие вопросы:
    \begin{itemize}
        \item Почему~$L_1$-регуляризация производит отбор признаков?
        \item Почему коэффициент регуляризации нельзя подбирать по обучающей выборке?
        \item Что такое кросс-валидация, чем она лучше использования отложенной выборки?
        \item Почему категориальные признаки нельзя закодировать натуральными числами? Что такое one-hot encoding?
        \item Для чего нужно масштабировать матрицу объекты-признаки перед обучением моделей машинного обучения?
        \item Почему MSE чувствительно к выбросам?
        \item Что такое Huber Loss? В чем его преимущества по сравнению с MAE и MSE?
        \item Почему квантильная регрессия так называется?
    \end{itemize}
\end{esProblem}

\end{document}
